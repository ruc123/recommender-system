{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "messages = pd.read_csv('projectdata.csv', encoding = 'latin-1')\n",
    "train = pd.read_csv('traindata.csv', encoding = 'latin-1')\n",
    "test = pd.read_csv('testdata.csv', encoding = 'latin-1')\n",
    "\n",
    "from textblob import Word\n",
    "\n",
    "def dataprocess(message, lower_case = True, stem = True, stop_words = True, gram = 1, lem = True):\n",
    "    if lower_case:\n",
    "        message = message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words = [w for w in words if len(w) > 2]\n",
    "    if gram > 1:\n",
    "        w = []\n",
    "        for i in range(len(words) - gram + 1):\n",
    "            w += [' '.join(words[i:i + gram])]\n",
    "        return w\n",
    "    if stop_words:\n",
    "        sw = stopwords.words('english')\n",
    "        words = [word for word in words if word not in sw]\n",
    "    if lem:\n",
    "        words = [Word(word).lemmatize() for word in words]\n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]   \n",
    "    return words\n",
    "#message = '? 1 wow!! going to school having fun arguing'\n",
    "#preprocess(message)\n",
    "\n",
    "class detect_spam(object):\n",
    "    def __init__(self, train):\n",
    "        self.message, self.score, self.len_train = train['message'], train['score'], len(train)\n",
    "    \n",
    "    def tfidf(self):\n",
    "        \n",
    "        self.totalspam, self.not_spam = self.score.value_counts()[1], self.score.value_counts()[0]\n",
    "        self.words1 = 0\n",
    "        self.words2 = 0\n",
    "        self.spamcount = {}\n",
    "        self.not_spamcount = {}\n",
    "        self.idf_spam = {}\n",
    "        self.idf_not_spam = {}\n",
    "        self.spamprob = {}\n",
    "        self.notspam_prob = {}\n",
    "        self.sum_prob_spam = 0\n",
    "        self.sum_prob_notspam = 0\n",
    "        for i in range(self.len_train):\n",
    "            processed = dataprocess(self.message[i])\n",
    "            count = [] #to find idf whether the word is in message or not\n",
    "            for word in processed:\n",
    "                if self.score[i]:\n",
    "                    self.spamcount[word] = self.spamcount.get(word, 0) + 1\n",
    "                    self.words1 += 1\n",
    "                else:\n",
    "                    self.not_spamcount[word] = self.not_spamcount.get(word, 0) + 1\n",
    "                    self.words2 += 1\n",
    "                if word not in count:\n",
    "                    count += [word]\n",
    "            for word in count:\n",
    "                if self.score[i]:\n",
    "                    self.idf_spam[word] = self.idf_spam.get(word, 0) + 1\n",
    "                else:\n",
    "                    self.idf_not_spam[word] = self.idf_not_spam.get(word, 0) + 1\n",
    "        \n",
    "        \n",
    "        for word in self.spamcount:\n",
    "            self.spamprob[word] = (self.spamcount[word]) * log((self.len_train) / (self.idf_spam[word] + self.idf_not_spam.get(word, 0)))\n",
    "            self.sum_prob_spam += self.spamprob[word]\n",
    "        for word in self.spamcount:\n",
    "            self.spamprob[word] = (self.spamprob[word] + 1) / (self.sum_prob_spam + len(list(self.spamprob.keys())))\n",
    "            \n",
    "        for word in self.not_spamcount:\n",
    "            self.notspam_prob[word] = (self.not_spamcount[word]) * log((self.len_train) \\\n",
    "                                                          / (self.idf_spam.get(word, 0) + self.idf_not_spam[word]))\n",
    "            self.sum_prob_notspam += self.notspam_prob[word]\n",
    "        for word in self.not_spamcount:\n",
    "            self.notspam_prob[word] = (self.notspam_prob[word] + 1) / (self.sum_prob_notspam + len(list(self.notspam_prob.keys())))\n",
    "            \n",
    "    \n",
    "        self.prob_spam_mail, self.prob_ham_mail = self.totalspam / self.len_train, self.not_spam / self.len_train \n",
    "    \n",
    "    def compare_prob(self, processed_message):\n",
    "        finalprob_spam, finalprob_notspam = 0, 0\n",
    "        for word in processed_message:                \n",
    "            if word in self.spamprob:\n",
    "                finalprob_spam += log(self.spamprob[word])\n",
    "            else:\n",
    "                finalprob_spam -= log(self.sum_prob_spam + len(list(self.spamprob.keys())))\n",
    "                \n",
    "            if word in self.notspam_prob:\n",
    "                finalprob_notspam += log(self.notspam_prob[word])\n",
    "            else:\n",
    "                finalprob_notspam -= log(self.sum_prob_notspam + len(list(self.notspam_prob.keys()))) \n",
    "                \n",
    "            finalprob_spam += log(self.prob_spam_mail)\n",
    "            finalprob_notspam += log(self.prob_ham_mail)\n",
    "            \n",
    "        return finalprob_spam >= finalprob_notspam\n",
    "    \n",
    "    def predict(self, testmessage):\n",
    "        predictions = {}\n",
    "        for (i, message) in enumerate(testmessage):\n",
    "            processed_message = dataprocess(message)\n",
    "            predictions[i] = int(self.compare_prob(processed_message))\n",
    "        return predictions\n",
    "    \n",
    "    def confusion_mat(self, testdata, prediction):\n",
    "        true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0\n",
    "        for i in range(len(testdata)):\n",
    "            true_pos += int(testdata[i] == 1 and prediction[i] == 1)\n",
    "            true_neg += int(testdata[i] == 0 and prediction[i] == 0)\n",
    "            false_pos += int(testdata[i] == 0 and prediction[i] == 1)\n",
    "            false_neg += int(testdata[i] == 1 and prediction[i] == 0)\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "        recall = true_pos / (true_pos + false_neg)\n",
    "        Fscore = 2 * precision * recall / (precision + recall)\n",
    "        accuracy = (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)\n",
    "        TPR = true_pos / (true_pos + false_neg)\n",
    "        FPR = false_pos / (false_pos + true_neg )\n",
    "\n",
    "        print(\"Precision: \", precision)\n",
    "        print(\"Recall: \", recall)\n",
    "        print(\"F-score: \", Fscore)\n",
    "        print(\"Accuracy: \", accuracy)\n",
    "        print(\"TPR:\", TPR)\n",
    "        print(\"FPR:\", FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9369369369369369\n",
      "Recall:  0.7074829931972789\n",
      "F-score:  0.8062015503875969\n",
      "Accuracy:  0.9551569506726457\n",
      "TPR: 0.7074829931972789\n",
      "FPR: 0.007231404958677686\n"
     ]
    }
   ],
   "source": [
    "call = detect_spam(train)\n",
    "call.tfidf()\n",
    "pred = call.predict(test['message'])\n",
    "call.confusion_mat(test['score'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "pm = dataprocess('URGENT! Your Mobile No. was awarded å£2000 Bonus')\n",
    "print(call.compare_prob(pm))\n",
    "\n",
    "pm = dataprocess('Going for dinner')\n",
    "print(call.compare_prob(pm))\n",
    "\n",
    "pm = dataprocess('You are a winner. You have been specially selected to receive money')\n",
    "print(call.compare_prob(pm))\n",
    "\n",
    "pm = dataprocess('I am going to see you today')\n",
    "print(call.compare_prob(pm))\n",
    "\n",
    "pm = dataprocess('Reply with your name and address and receive award')\n",
    "print(call.compare_prob(pm))\n",
    "\n",
    "pm = dataprocess('Hi,This exclusive download is not available to the general public.This is your Private Access Only. Click Here To Get Instant Access Now. Only One Download License Per User Member Solutions. Talk soon,')\n",
    "print(call.compare_prob(pm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
